import os
import re
import json
from typing import List, Dict, Tuple, Optional
from loguru import logger


class AnnualReportChunker:
    """å¹´æŠ¥ç»“æ„åŒ–åˆ†å—å™¨"""

    def __init__(self):
        # å¹´æŠ¥å¸¸è§ç« èŠ‚æ ‡é¢˜æ¨¡å¼ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
        self.section_patterns = [
            # ç¬¬XèŠ‚ æ ¼å¼ï¼ˆæœ€æ˜ç¡®ï¼‰
            r'^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+èŠ‚\s+\S.*$',
            r'^ç¬¬\d+\s*èŠ‚\s+\S.*$',

            # Markdownæ ‡é¢˜æ ¼å¼
            r'^#+\s+\S.*$',  # # æ ‡é¢˜

            # ä¸€çº§æ ‡é¢˜ï¼šä¸­æ–‡æ•°å­— + ã€
            r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+[ã€ï¼.]\s+\S.*$',  # ç¡®ä¿æ ‡é¢˜åæœ‰å†…å®¹

            # ç›®å½•/é‡è¦æç¤º/é‡Šä¹‰ï¼ˆå•ç‹¬æˆè¡Œï¼‰
            r'^é‡è¦æç¤º\s*$',
            r'^ç›®å½•\s*$',
            r'^é‡Šä¹‰\s*$',

            # å¸¸è§ç« èŠ‚åç§°ï¼ˆå®Œæ•´åŒ¹é…ï¼‰
            r'^å…¬å¸ç®€ä»‹\s*$',
            r'^ä¼šè®¡æ•°æ®\s*$',
            r'^è´¢åŠ¡æŠ¥å‘Š\s*$',
            r'^è‘£äº‹ä¼šæŠ¥å‘Š\s*$',
            r'^ç›‘äº‹ä¼šæŠ¥å‘Š\s*$',
            r'^é‡è¦äº‹é¡¹\s*$',
            r'^è‚¡æœ¬å˜åŠ¨\s*$',
            r'^è‚¡ä¸œä¿¡æ¯\s*$',
            r'^å…¬å¸å€ºåˆ¸\s*$',
            r'^è´¢åŠ¡æŠ¥è¡¨\s*$',
        ]

        # å­ç« èŠ‚æ ‡é¢˜æ¨¡å¼ï¼ˆç”¨äºè¯†åˆ«å°èŠ‚ï¼‰
        self.subsection_patterns = [
            r'^#+\s+\S.*$',  # Markdownæ ‡é¢˜
            r'^[ï¼ˆ(][ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+[)ï¼‰]\s*.+',
            r'^[ï¼ˆ(]\d+[)ï¼‰]\s*.+',
            r'^[â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]\s*.+',
        ]

        # è¡¨æ ¼ç›¸å…³å…³é”®è¯
        self.table_header_keywords = [
            'é¡¹ç›®', 'ç§‘ç›®', 'åç§°', 'è¯´æ˜', 'é™„æ³¨', 'å•ä½', 'å¸ç§',
            'é‡‘é¢', 'æ•°é‡', 'æ¯”ä¾‹', 'æ¯”ç‡', '%', 'å…ƒ', 'ä¸‡å…ƒ', 'äº¿å…ƒ'
        ]

        self.finance_keywords = [
            'èµ„äº§', 'è´Ÿå€º', 'æƒç›Š', 'æ‰€æœ‰è€…æƒç›Š', 'èµ„äº§è´Ÿå€ºè¡¨',
            'åˆ©æ¶¦', 'æŸç›Š', 'æ”¶å…¥', 'æˆæœ¬', 'è´¹ç”¨', 'åˆ©æ¶¦è¡¨', 'æŸç›Šè¡¨',
            'ç°é‡‘æµ', 'ç°é‡‘æµé‡è¡¨', 'è‚¡ä¸œ', 'è‚¡æœ¬', 'è‚¡ä»½'
        ]

    def is_section_title(self, line: str) -> Tuple[bool, str]:
        """
        åˆ¤æ–­ä¸€è¡Œæ˜¯å¦æ˜¯ç« èŠ‚æ ‡é¢˜
        è¿”å›: (æ˜¯å¦æ˜¯æ ‡é¢˜, æ ‡é¢˜çº§åˆ«: 'main'/'sub'/'none')
        """
        line = line.strip()

        # æ£€æŸ¥æ˜¯å¦æ˜¯ä¸€çº§ç« èŠ‚æ ‡é¢˜
        for pattern in self.section_patterns:
            if re.match(pattern, line):
                return True, 'main'

        # æ£€æŸ¥æ˜¯å¦æ˜¯å­ç« èŠ‚æ ‡é¢˜
        for pattern in self.subsection_patterns:
            if re.match(pattern, line):
                return True, 'sub'

        return False, 'none'

    def clean_line(self, line: str) -> str:
        """æ¸…ç†è¡Œå†…å®¹"""
        line = line.strip()
        # ç§»é™¤å¤šä½™ç©ºæ ¼
        line = re.sub(r'\s+', ' ', line)
        return line

    def is_markdown_metadata(self, line: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯Markdownå…ƒæ•°æ®"""
        line = line.strip()
        return line.startswith('---') or line.startswith('```') or line.startswith('|--')

    def extract_sections_from_text(self, text: str) -> List[Dict]:
        """
        ä»çº¯æ–‡æœ¬ä¸­æå–ç« èŠ‚
        è¿”å›: [{'title': ç« èŠ‚æ ‡é¢˜, 'level': çº§åˆ«, 'content': å†…å®¹, 'lines': è¡Œå·åˆ—è¡¨}]
        """
        lines = text.split('\n')
        sections = []
        current_section = None
        line_number = 0

        for line in lines:
            line_number += 1
            line = self.clean_line(line)

            # è·³è¿‡ç©ºè¡Œå’ŒMarkdownå…ƒæ•°æ®
            if not line or self.is_markdown_metadata(line):
                continue

            # æ£€æŸ¥æ˜¯å¦æ˜¯ç« èŠ‚æ ‡é¢˜
            is_title, level = self.is_section_title(line)

            if is_title:
                # ä¿å­˜ä¸Šä¸€ä¸ªç« èŠ‚
                if current_section:
                    sections.append(current_section)

                # åˆ›å»ºæ–°ç« èŠ‚
                current_section = {
                    'title': line,
                    'level': level,
                    'content': '',
                    'lines': [line_number],
                    'char_start': len(text[:text.index(line)]) if line in text else 0
                }
            else:
                # æ·»åŠ åˆ°å½“å‰ç« èŠ‚
                if current_section:
                    current_section['content'] += line + '\n'
                    current_section['lines'].append(line_number)
                else:
                    # æ–‡æ¡£å¼€å¤´çš„å†…å®¹ï¼ˆåœ¨ç¬¬ä¸€ä¸ªç« èŠ‚ä¹‹å‰çš„ï¼‰
                    current_section = {
                        'title': 'æ–‡æ¡£å¼€å¤´',
                        'level': 'main',
                        'content': line + '\n',
                        'lines': [line_number],
                        'char_start': 0
                    }

        # ä¿å­˜æœ€åä¸€ä¸ªç« èŠ‚
        if current_section:
            sections.append(current_section)

        return sections

    def merge_small_sections(self, sections: List[Dict], min_chars: int = 200) -> List[Dict]:
        """
        æ”¹è¿›çš„ç« èŠ‚åˆå¹¶ï¼šä¸åˆå¹¶åŒ…å«è¡¨æ ¼çš„ç« èŠ‚
        min_chars: æœ€å°å­—ç¬¦æ•°ï¼Œå°äºæ­¤å€¼çš„ç« èŠ‚ä¼šè¢«åˆå¹¶
        """
        if not sections:
            return sections

        merged = []
        i = 0

        while i < len(sections):
            current = sections[i]

            # æ£€æŸ¥å½“å‰ç« èŠ‚æ˜¯å¦åŒ…å«è¡¨æ ¼
            current_has_table = '|' in current['content']

            # å¦‚æœå½“å‰ç« èŠ‚å¤ªå°ä¸”ä¸æ˜¯ç¬¬ä¸€ä¸ª
            if len(current['content']) < min_chars and merged and not current_has_table:
                last_section = merged[-1]
                last_has_table = '|' in last_section['content']

                # å¦‚æœä¸Šä¸€ä¸ªç« èŠ‚æœ‰è¡¨æ ¼ï¼Œä¸åˆå¹¶ï¼ˆä¿æŒè¡¨æ ¼ç‹¬ç«‹ï¼‰
                if last_has_table:
                    merged.append(current)
                else:
                    # åˆå¹¶é€»è¾‘
                    last_section['content'] += '\n\n' + current['content']
                    # æ ‡é¢˜å¤„ç†ï¼šä½¿ç”¨æ›´æœ‰æ„ä¹‰çš„åˆå¹¶
                    if '+' not in last_section['title']:
                        last_section['title'] = f"{last_section['title']} [+ {current['title']}]"
                    else:
                        # å¦‚æœå·²ç»æœ‰åˆå¹¶æ ‡è®°ï¼Œç®€åŒ–æ˜¾ç¤º
                        last_section['title'] = last_section['title'].split(' [')[0] + ' [...]'
                    last_section['lines'].extend(current['lines'])
            else:
                merged.append(current)

            i += 1

        return merged

    def chunk_by_sections(
            self,
            text: str,
            min_chars: int = 100,
            max_chars: int = 3000,
            merge_small: bool = True
    ) -> List[Dict]:
        """
        æŒ‰ç« èŠ‚è¿›è¡Œåˆ†å—

        å‚æ•°:
            text: è¾“å…¥æ–‡æœ¬
            min_chars: æœ€å°å­—ç¬¦æ•°ï¼ˆç”¨äºåˆå¹¶å°ç« èŠ‚ï¼‰
            max_chars: æœ€å¤§å­—ç¬¦æ•°ï¼ˆè¶…è¿‡æ­¤å¤§å°çš„ç« èŠ‚ä¼šè¿›ä¸€æ­¥åˆ†å‰²ï¼‰
            merge_small: æ˜¯å¦åˆå¹¶å°ç« èŠ‚

        è¿”å›:
            ç« èŠ‚å—åˆ—è¡¨
        """
        # æå–ç« èŠ‚
        sections = self.extract_sections_from_text(text)

        if merge_small:
            sections = self.merge_small_sections(sections, min_chars)

        # å¯¹è¿‡å¤§çš„ç« èŠ‚è¿›è¡Œåˆ†å‰²
        final_chunks = []
        for section in sections:
            if len(section['content']) <= max_chars:
                final_chunks.append(section)
            else:
                # åˆ†å‰²å¤§ç« èŠ‚
                sub_chunks = self.split_large_section(section, max_chars)
                final_chunks.extend(sub_chunks)

        return final_chunks

    def split_large_section(self, section: Dict, max_chars: int) -> List[Dict]:
        """
        å°†è¿‡å¤§çš„ç« èŠ‚åˆ†å‰²æˆå¤šä¸ªå—
        ç­–ç•¥ï¼š
        1. å…ˆæŒ‰å­ç« èŠ‚åˆ†å‰²ï¼ˆå¦‚æœæœ‰ï¼‰
        2. å†æŒ‰æ®µè½åˆ†å‰²ï¼Œä¿æŠ¤è¡¨æ ¼å®Œæ•´æ€§
        """
        content = section['content']
        title = section['title']
        level = section['level']

        # æ£€æŸ¥æ˜¯å¦æœ‰Markdownæ ‡é¢˜ä½œä¸ºå­ç« èŠ‚
        lines = content.split('\n')
        has_subheadings = any(re.match(r'^#+\s+', line.strip()) for line in lines)

        if has_subheadings:
            return self._split_by_markdown_headings(section, max_chars)

        # æ²¡æœ‰å­ç« èŠ‚ï¼ŒæŒ‰æ™ºèƒ½æ®µè½åˆ†å‰²ï¼ˆåŒ…å«è¡¨æ ¼ä¿æŠ¤ï¼‰
        return self._split_by_smart_paragraphs(title, content, level, max_chars)

    def _split_by_markdown_headings(self, section: Dict, max_chars: int) -> List[Dict]:
        """æŒ‰Markdownæ ‡é¢˜åˆ†å‰²å¤§ç« èŠ‚"""
        content = section['content']
        title = section['title']
        level = section['level']

        chunks = []
        current_content = ''
        current_heading = title
        chunk_num = 1

        lines = content.split('\n')
        for line in lines:
            # æ£€æŸ¥æ˜¯å¦æ˜¯Markdownæ ‡é¢˜
            if re.match(r'^#+\s+', line.strip()):
                # ä¿å­˜å½“å‰å—
                if current_content.strip():
                    chunks.append({
                        'title': current_heading,
                        'content': current_content.strip(),
                        'level': level
                    })
                    chunk_num += 1

                # å¼€å§‹æ–°å—
                current_heading = f"{title} - {line.strip()}"
                current_content = line + '\n'
            else:
                current_content += line + '\n'

        # ä¿å­˜æœ€åä¸€å—
        if current_content.strip():
            chunks.append({
                'title': current_heading,
                'content': current_content.strip(),
                'level': level
            })

        return chunks

    def _split_by_smart_paragraphs(self, title: str, content: str, level: str, max_chars: int) -> List[Dict]:
        """
        æ™ºèƒ½æŒ‰æ®µè½åˆ†å‰²ï¼Œå®Œæ•´ä¿æŠ¤è¡¨æ ¼ç»“æ„ (å·²ä¿®å¤æ­»å¾ªç¯Bug)
        """
        lines = content.split('\n')
        chunks = []
        current_chunk_lines = []
        current_size = 0
        chunk_num = 1

        i = 0
        while i < len(lines):
            line = lines[i]
            line_size = len(line)

            # ğŸ”´ã€æ£€æµ‹è¡¨æ ¼å¼€å§‹ã€‘
            if self._is_table_start(line, i, lines):
                # æ‰¾åˆ°è¡¨æ ¼ç»“æŸä½ç½®
                table_start = i
                table_end = self._find_table_end(i, lines)

                # ğŸ”¥ã€å…³é”®ä¿®å¤ã€‘ï¼šé˜²æ­¢æ­»å¾ªç¯
                # å¦‚æœæ£€æµ‹é€»è¾‘çŸ›ç›¾ï¼Œfind_table_end è¿”å›äº†åŸåœ°ï¼Œæˆ–è€…æ²¡æœ‰å‰è¿›
                if table_end <= table_start:
                    # æ­¤æ—¶è¢«è¯¯åˆ¤ä¸ºè¡¨æ ¼å¤´ï¼Œä½†å®é™…ä¸Šæ— æ³•æå–è¡¨æ ¼
                    # å½“ä½œæ™®é€šæ–‡æœ¬å¤„ç†ï¼Œå¼ºåˆ¶è·³è¿‡å½“å‰è¡Œ
                    current_chunk_lines.append(line)
                    current_size += line_size
                    i += 1
                    continue

                # æå–å®Œæ•´è¡¨æ ¼
                table_lines = lines[table_start:table_end]
                table_content = '\n'.join(table_lines)

                # 1. å…ˆä¿å­˜å½“å‰å·²ç§¯ç´¯çš„æ–‡æœ¬å—
                if current_chunk_lines:
                    chunks.append({
                        'title': f"{title} ({chunk_num})" if chunk_num > 1 else title,
                        'content': '\n'.join(current_chunk_lines),
                        'level': level,
                        'has_table': False
                    })
                    chunk_num += 1
                    current_chunk_lines = []
                    current_size = 0

                # 2. ä¿å­˜è¡¨æ ¼å—
                table_title = f"{title} - è¡¨æ ¼({chunk_num})"
                if chunk_num == 1:
                    table_title = f"{title} - è¡¨æ ¼"

                chunks.append({
                    'title': table_title,
                    'content': table_content,
                    'level': level,
                    'has_table': True,
                    'table_type': self._detect_table_type(table_lines)
                })
                chunk_num += 1

                # 3. ç§»åŠ¨ç´¢å¼•åˆ°è¡¨æ ¼ç»“æŸå¤„
                i = table_end
                continue

            # --- æ™®é€šæ®µè½å¤„ç†é€»è¾‘ ---
            if current_size + line_size > max_chars and current_chunk_lines:
                chunks.append({
                    'title': f"{title} ({chunk_num})" if chunk_num > 1 else title,
                    'content': '\n'.join(current_chunk_lines),
                    'level': level,
                    'has_table': False
                })
                chunk_num += 1
                current_chunk_lines = []
                current_size = 0

            current_chunk_lines.append(line)
            current_size += line_size
            i += 1

        # ä¿å­˜æœ€åä¸€å—
        if current_chunk_lines:
            chunks.append({
                'title': f"{title} ({chunk_num})" if chunk_num > 1 else title,
                'content': '\n'.join(current_chunk_lines),
                'level': level,
                'has_table': False
            })

        return chunks

    def _is_table_start(self, line: str, index: int, lines: List[str]) -> bool:
        """
        æ£€æµ‹æ˜¯å¦æ˜¯è¡¨æ ¼å¼€å§‹
        Markdownè¡¨æ ¼ç‰¹å¾ï¼š
        1. ä»¥ | å¼€å¤´æˆ–åŒ…å« |
        2. ä¸‹ä¸€è¡Œæ˜¯åˆ†éš”çº¿ï¼ˆåŒ…å« - å’Œ |ï¼‰
        """
        line = line.strip()

        # 1. å¿…é¡»æœ‰|ç¬¦å·
        if '|' not in line:
            return False

        # 2. æ’é™¤æŸäº›ç‰¹æ®Šæƒ…å†µ
        # - æ’é™¤ç« èŠ‚æ ‡é¢˜
        if self.is_section_title(line)[0]:
            return False

        # - æ’é™¤åˆ—è¡¨é¡¹
        if re.match(r'^[*-]\s+', line):
            return False

        # 3. æ£€æŸ¥è¡¨æ ¼ç‰¹å¾
        pipe_count = line.count('|')

        # 3.1 æ£€æŸ¥æ˜¯å¦æ˜¯ç®€å•çš„è¡¨æ ¼è¡Œï¼ˆåˆ—æ•°åˆç†ï¼‰
        if pipe_count < 2 or pipe_count > 30:  # 2-30åˆ—ä¹‹é—´
            return False

        # 3.2 æ£€æŸ¥æ˜¯å¦åŒ…å«è¡¨æ ¼å†…å®¹ï¼ˆæ•°å­—ã€ä¸­æ–‡ã€ç©ºæ ¼ï¼‰
        # ç§»é™¤|ç¬¦å·å’Œç©ºæ ¼ï¼Œæ£€æŸ¥å‰©ä½™å†…å®¹
        content = line.replace('|', '').replace(' ', '')
        if not content:
            return False

        # 3.3 æ£€æŸ¥ä¸‹ä¸€è¡Œæ˜¯å¦æ˜¯åˆ†éš”çº¿
        if index + 1 < len(lines):
            next_line = lines[index + 1].strip()
            if '|' in next_line:
                # è®¡ç®—åˆ†éš”çº¿ç‰¹å¾ï¼šåŒ…å«å¤šä¸ªè¿ç»­çš„-æˆ–=
                sep_pattern = r'[-=]+'
                sep_parts = re.split(r'\|', next_line)
                if len(sep_parts) > 1:
                    has_separator = any(re.match(sep_pattern, part.strip()) for part in sep_parts if part.strip())
                    if has_separator:
                        return True

        # 3.4 æ£€æŸ¥æ˜¯å¦æ˜¯è´¢æŠ¥è¡¨æ ¼ï¼ˆåŒ…å«å…³é”®è¯ï¼‰
        finance_keywords = self.finance_keywords + self.table_header_keywords
        if any(keyword in line for keyword in finance_keywords):
            # ç¡®è®¤æœ‰è¶³å¤Ÿçš„åˆ—
            if pipe_count >= 3:
                return True

        # 3.5 æ£€æŸ¥æ˜¯å¦æ˜¯è¿ç»­è¡¨æ ¼è¡Œ
        if index > 0:
            prev_line = lines[index - 1].strip()
            if '|' in prev_line and not self.is_section_title(prev_line)[0]:
                # ä¸Šä¸€è¡Œä¹Ÿæ˜¯è¡¨æ ¼è¡Œï¼Œä¸”ä¸æ˜¯æ ‡é¢˜
                # æ£€æŸ¥æ˜¯å¦æœ‰åˆç†çš„è¡¨æ ¼å†…å®¹
                prev_parts = [p.strip() for p in prev_line.split('|') if p.strip()]
                curr_parts = [p.strip() for p in line.split('|') if p.strip()]
                if len(prev_parts) >= 2 and len(curr_parts) >= 2:
                    return True

        return False

    def _find_table_end(self, start_index: int, lines: List[str]) -> int:
        """
        ç²¾ç¡®æ‰¾åˆ°è¡¨æ ¼ç»“æŸä½ç½®
        """
        i = start_index
        consecutive_table_rows = 0

        while i < len(lines):
            line = lines[i].strip()

            # ç©ºè¡Œä¸”å·²ç»æœ‰è¡¨æ ¼å†…å®¹ï¼Œåˆ™ç»“æŸ
            if not line and consecutive_table_rows > 0:
                return i

            # æ£€æŸ¥æ˜¯å¦æ˜¯è¡¨æ ¼è¡Œ
            is_table_row = self._is_table_row(line, i, lines)

            if is_table_row:
                consecutive_table_rows += 1
                i += 1
                continue
            else:
                # ä¸æ˜¯è¡¨æ ¼è¡Œ
                if consecutive_table_rows > 0:
                    # å·²ç»æœ‰è¡¨æ ¼å†…å®¹ï¼Œå½“å‰è¡Œä¸æ˜¯è¡¨æ ¼ï¼Œç»“æŸè¡¨æ ¼
                    return i
                else:
                    # æ ¹æœ¬æ²¡æœ‰è¡¨æ ¼ï¼Œè¿”å›åŸä½ç½®
                    return start_index

            i += 1

        return len(lines)

    def _is_table_row(self, line: str, index: int, lines: List[str]) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦æ˜¯è¡¨æ ¼è¡Œï¼ˆæ¯”_startæ›´å®½æ¾ï¼Œç”¨äºæ£€æµ‹è¿ç»­è¡¨æ ¼è¡Œï¼‰
        """
        if not line or '|' not in line:
            return False

        # æ’é™¤æ˜æ˜¾ä¸æ˜¯è¡¨æ ¼çš„æƒ…å†µ
        if line.startswith('#') or self.is_section_title(line)[0]:
            return False

        # æ£€æŸ¥æ˜¯å¦æœ‰åˆç†çš„å†…å®¹
        parts = [p.strip() for p in line.split('|') if p.strip()]

        # ç©ºå•å…ƒæ ¼å¤ªå¤šçš„æƒ…å†µæ’é™¤
        if len(parts) < 2:
            return False

        # æ£€æŸ¥å†…å®¹ç‰¹å¾
        # è¡¨æ ¼å†…å®¹é€šå¸¸åŒ…å«ï¼šæ•°å­—ã€ä¸­æ–‡ã€å°‘é‡ç‰¹æ®Šå­—ç¬¦
        valid_content = False
        for part in parts:
            if part:
                # åŒ…å«æ•°å­—æˆ–ä¸­æ–‡
                if re.search(r'[\dä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡äº¿%.,]', part) or re.search(r'[\u4e00-\u9fff]', part):
                    valid_content = True
                    break

        return valid_content

    def _detect_table_type(self, table_lines: List[str]) -> str:
        """
        æ£€æµ‹è¡¨æ ¼ç±»å‹
        """
        if not table_lines:
            return 'unknown'

        # æ£€æŸ¥å¸¸è§çš„è´¢åŠ¡æŠ¥è¡¨è¡¨å¤´
        # æŸ¥çœ‹å‰3è¡Œï¼Œå› ä¸ºå¯èƒ½æœ‰å¤æ‚çš„å¤šè¡Œè¡¨å¤´
        header_text = ' '.join(table_lines[:min(3, len(table_lines))]).lower()

        if any(keyword in header_text for keyword in ['èµ„äº§', 'è´Ÿå€º', 'æ‰€æœ‰è€…æƒç›Š', 'èµ„äº§è´Ÿå€ºè¡¨']):
            return 'balance_sheet'
        elif any(keyword in header_text for keyword in ['åˆ©æ¶¦', 'æŸç›Š', 'æ”¶å…¥', 'è´¹ç”¨', 'åˆ©æ¶¦è¡¨', 'æŸç›Šè¡¨']):
            return 'income_statement'
        elif any(keyword in header_text for keyword in ['ç°é‡‘æµ', 'ç°é‡‘', 'ç°é‡‘æµé‡']):
            return 'cash_flow'
        elif any(keyword in header_text for keyword in ['è‚¡ä¸œ', 'è‚¡æœ¬', 'è‚¡ä»½', 'æ‰€æœ‰è€…æƒç›Šå˜åŠ¨']):
            return 'equity'
        elif any(keyword in header_text for keyword in ['å®¡è®¡', 'ä¼šè®¡å¸ˆ', 'å®¡è®¡æŠ¥å‘Š']):
            return 'audit'
        else:
            return 'general'

    def chunk_by_sections_with_sliding_window(
            self,
            text: str,
            section_max_chars: int = 2000,
            sliding_window_size: int = 1000,
            sliding_overlap: int = 200,
            merge_small: bool = True
    ) -> List[Dict]:
        """
        æ··åˆåˆ†å—ç­–ç•¥ï¼šå…ˆç»“æ„åŒ–åˆ†å—ï¼Œå¤§ç« èŠ‚ä½¿ç”¨æ»‘çª—

        å‚æ•°:
            text: è¾“å…¥æ–‡æœ¬
            section_max_chars: ç« èŠ‚æœ€å¤§å­—ç¬¦æ•°ï¼Œè¶…è¿‡åˆ™ä½¿ç”¨æ»‘çª—
            sliding_window_size: æ»‘çª—å¤§å°
            sliding_overlap: æ»‘çª—é‡å å¤§å°
            merge_small: æ˜¯å¦åˆå¹¶å°ç« èŠ‚

        è¿”å›:
            åˆ†å—åˆ—è¡¨
        """
        # 1. å…ˆè¿›è¡Œç»“æ„åŒ–åˆ†å—
        sections = self.extract_sections_from_text(text)

        if merge_small:
            sections = self.merge_small_sections(sections, min_chars=100)

        # 2. å¯¹æ¯ä¸ªç« èŠ‚åˆ¤æ–­æ˜¯å¦éœ€è¦æ»‘çª—
        final_chunks = []
        for section in sections:
            content_len = len(section['content'])

            if content_len <= section_max_chars:
                # å°ç« èŠ‚ï¼Œç›´æ¥ä¿ç•™
                final_chunks.append(section)
            else:
                # å¤§ç« èŠ‚ï¼Œä½¿ç”¨æ»‘çª—åˆ†å—
                logger.info(f'ç« èŠ‚ "{section["title"][:30]}..." å¤§å° {content_len} å­—ç¬¦ï¼Œä½¿ç”¨æ»‘çª—åˆ†å—')

                sliding_chunks = self._sliding_window_by_char(
                    title=section['title'],
                    content=section['content'],
                    level=section['level'],
                    chunk_size=sliding_window_size,
                    overlap=sliding_overlap
                )

                final_chunks.extend(sliding_chunks)

        return final_chunks

    def _sliding_window_by_char(
            self,
            title: str,
            content: str,
            level: str,
            chunk_size: int,
            overlap: int
    ) -> List[Dict]:
        """
        æŒ‰å­—ç¬¦æ»‘çª—åˆ†å—
        ä¼˜å…ˆåœ¨å¥å­/æ®µè½è¾¹ç•Œåˆ‡åˆ†
        """
        chunks = []
        start = 0
        content_len = len(content)
        chunk_num = 1

        while start < content_len:
            # è®¡ç®—çª—å£ç»“æŸä½ç½®
            end = min(start + chunk_size, content_len)

            # å¦‚æœä¸æ˜¯æœ€åä¸€å—ï¼Œå°è¯•åœ¨å¥å­è¾¹ç•Œåˆ‡åˆ†
            if end < content_len:
                # ä¼˜å…ˆæ‰¾æ®µè½è¾¹ç•Œï¼ˆ\n\nï¼‰
                paragraph_boundary = content.rfind('\n\n', start, end)
                if paragraph_boundary > start + chunk_size * 0.7:  # è‡³å°‘ä¿ç•™70%
                    end = paragraph_boundary + 2
                else:
                    # å…¶æ¬¡æ‰¾å¥å­è¾¹ç•Œï¼ˆå¥å·ï¼‰
                    sentence_boundary = content.rfind('ã€‚', start, end)
                    if sentence_boundary > start + chunk_size * 0.7:
                        end = sentence_boundary + 1
                    else:
                        # æœ€åæ‰¾æ¢è¡Œ
                        line_boundary = content.rfind('\n', start, end)
                        if line_boundary > start + chunk_size * 0.7:
                            end = line_boundary + 1

            # æå–çª—å£å†…å®¹
            chunk_content = content[start:end].strip()

            if chunk_content:
                chunks.append({
                    'title': f"{title} (æ»‘åŠ¨{chunk_num})" if chunk_num > 1 else title,
                    'content': chunk_content,
                    'level': level,
                    'char_range': [start, end],
                    'overlap': overlap if chunk_num > 1 else 0
                })
                chunk_num += 1

            # ç§»åŠ¨çª—å£ï¼ˆä¿ç•™é‡å ï¼‰
            start = end - overlap if end < content_len else content_len

        return chunks


def load_md_file(file_path: str) -> List[str]:
    """
    åŠ è½½Markdownæ–‡ä»¶

    å‚æ•°:
        file_path: Markdownæ–‡ä»¶è·¯å¾„

    è¿”å›:
        å†…å®¹åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸ºä¸€é¡µï¼ˆè¿™é‡Œå°†æ•´ä¸ªæ–‡ä»¶ä½œä¸ºä¸€é¡µå¤„ç†ï¼‰
    """
    try:
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()

        logger.info(f"æˆåŠŸåŠ è½½Markdownæ–‡ä»¶: {file_path} (å¤§å°: {len(content)} å­—ç¬¦)")
        return [content]  # è¿”å›åˆ—è¡¨æ ¼å¼ä»¥ä¿æŒæ¥å£ä¸€è‡´æ€§

    except FileNotFoundError:
        logger.error(f"æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")
        return []
    except Exception as e:
        logger.error(f"è¯»å–Markdownæ–‡ä»¶å¤±è´¥: {e}")
        return []


def find_md_files(data_path: str) -> List[str]:
    """
    åœ¨æŒ‡å®šç›®å½•ä¸‹æŸ¥æ‰¾æ‰€æœ‰Markdownæ–‡ä»¶

    å‚æ•°:
        data_path: æ•°æ®ç›®å½•è·¯å¾„

    è¿”å›:
        Markdownæ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    md_files = []

    # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡ä»¶
    if os.path.isfile(data_path) and data_path.endswith('.md'):
        return [data_path]

    # æ£€æŸ¥æ˜¯å¦ä¸ºç›®å½•
    if os.path.isdir(data_path):
        for file_name in os.listdir(data_path):
            if file_name.endswith('.md'):
                file_path = os.path.join(data_path, file_name)
                md_files.append(file_path)

    logger.info(f"åœ¨ {data_path} ä¸­æ‰¾åˆ° {len(md_files)} ä¸ªMarkdownæ–‡ä»¶")
    return md_files


def chunk_md_by_sections(file_path: str) -> List[Dict]:
    """
    å¯¹Markdownæ–‡ä»¶æŒ‰ç« èŠ‚è¿›è¡Œåˆ†å—

    å‚æ•°:
        file_path: Markdownæ–‡ä»¶è·¯å¾„

    è¿”å›:
        ç« èŠ‚å—åˆ—è¡¨
    """
    chunker = AnnualReportChunker()
    pages = load_md_file(file_path)

    if not pages:
        logger.warning(f'æœªåŠ è½½åˆ°é¡µé¢å†…å®¹: {file_path}')
        return []

    # åˆå¹¶æ‰€æœ‰é¡µé¢æ–‡æœ¬
    full_text = '\n\n'.join(pages)

    # æŒ‰ç« èŠ‚åˆ†å—
    chunks = chunker.chunk_by_sections(
        full_text,
        min_chars=100,
        max_chars=3000,
        merge_small=True
    )

    return chunks


def clean_text(text):
    """æ¸…ç†æ–‡æœ¬"""
    text = re.sub(r'\s+', ' ', text)
    return text.strip()


def get_text_chunks_from_md(file_path: str, save_json: bool = True) -> List[str]:
    """
    ä»Markdownæ–‡ä»¶è·å–æ–‡æœ¬åˆ†å—

    å‚æ•°:
        file_path: Markdownæ–‡ä»¶è·¯å¾„
        save_json: æ˜¯å¦ä¿å­˜ä¸ºJSONæ–‡ä»¶

    è¿”å›:
        æ ¼å¼åŒ–åçš„æ–‡æœ¬å—åˆ—è¡¨
    """
    pages = load_md_file(file_path)
    if not pages:
        return []

    full_text = "\n\n".join(pages)
    chunker = AnnualReportChunker()

    # æ‰§è¡Œç»“æ„åŒ–åˆ†å—
    structured_chunks = chunker.chunk_by_sections(
        full_text,
        min_chars=200,
        max_chars=800,
        merge_small=True
    )

    # --- ä¿å­˜ JSON æ–‡ä»¶ ---
    if save_json:
        # ä»æ–‡ä»¶è·¯å¾„ç”ŸæˆJSONæ–‡ä»¶å
        base_name = os.path.splitext(os.path.basename(file_path))[0]
        json_filename = f"{base_name}_chunks.json"

        # ä¿å­˜åˆ°åŒç›®å½•
        output_dir = os.path.dirname(file_path) or '.'
        output_path = os.path.join(output_dir, json_filename)

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(structured_chunks, f, ensure_ascii=False, indent=4)
        logger.info(f"åˆ†å— JSON å·²ä¿å­˜è‡³: {output_path}")

    # æ ¼å¼è½¬æ¢ä¾›æ£€ç´¢ä½¿ç”¨
    final_text_list = []
    for item in structured_chunks:
        title = item.get('title', 'æœªçŸ¥ç« èŠ‚')
        content = item.get('content', '').strip()
        has_table = item.get('has_table', False)
        table_type = item.get('table_type', '')

        if has_table:
            formatted_text = f"ã€è¡¨æ ¼ï¼š{table_type}ã€‘\n{content}"
        else:
            formatted_text = f"ã€ç« èŠ‚ï¼š{title}ã€‘\n{content}"
        final_text_list.append(formatted_text)

    logger.info(f"ç»“æ„åŒ–åˆ†å—å®Œæˆï¼Œå…±ç”Ÿæˆ {len(final_text_list)} ä¸ªåˆ‡ç‰‡")
    return final_text_list
